---
title: Hello World
---

要进行机器学习，就首先得有数据，假定我们收集到了孔子哥的数据. 那么（脸=帅，腿=长，性格=儒雅随和）括号内是一条记录，”=”的意思为取值为

  那么如果收集多了多组记录，那我们就把这组记录的集合体称为”数据集”（date set），其中每条记录是关于一个事件或者对象的描述，我们把它称为一个”示例”（instance）或者是”样本”(sample). 反应事件或对象在某方面的表现或性质的事项，例如”脸””性格”和”腿”则称为”属性”（attribute）或者”特征”（feature）;属性张成的空间称为”属性空间”（attribute space）丶”样本空间”(sample space)或”输入空间”，例如我们把”脸”腿”性格”作为三个坐标轴，则他们张成一个用于描述孔子哥的三维空间，每个数据都可以在这个空间内找到自己的坐标位置. 由于空间中的每个点对应一个坐标向量，因此我们也把一个示例成为一个”特征向量”（feature  vector）

 令D={x1,x2,....xm}表示包含m个示例的数据集，每个示例由d个属性描述（例如上面的孔子哥使用了三个属性），则每个示例xi=（xi1；xi2...；xi3）是d维样本空间X中的一个向量,xi∈X，其中xij是xi在第j个属性上的取值（例如上述孔子哥的第二个属性上的取值是”长”），d称为样本xi的”维数”（dimensionality）

 通过一个学习算法（learning algorithm）A，在训练集上找到一组参数θ，使得函数f(x, θ∗)可以近似真实的映射关系。这个过程称为学习（learning）或 训练（training）过程，函数f(x, θ)称为模型（model）

 如果希望学得一个能帮助我们判断孔子哥手部特征的模型，仅有前面的示例数据明显是不够的，要建立这样的关于”预测”(prediction)的模型，我们需要获得训练样本的”结果”信息，例如（（脸=帅；腿=长；性格=儒雅随和），好手）.这里关于示例结果的信息，例如”好手”，称为”标记”（label）；拥有了标记信息的示例，则称为”样例”（example），一般的，用（xi，yi）表示第i个示例，其中yi∈Y是示例xi的标记，Y所有标记的集合，又称为”标记空间”（label space）或”输出空间

 若我们欲预测的是离散值，例如”好手””坏手”，此类学习任务称为”分类”（classification）；若欲预测的是连续值，例如孔子哥有几根手指4，6，此类学习任务称为”回归”（regression）

对只涉及两个类别的”二分类”（binary classification）任务，通常称其中一个类为”正类”（positive class），另一个类为”反类”（negative class）；涉及多个类别时，则称为”多分类”（multi-class classification）任务，一般的，预测任务是希望通过对训练集{(x1,y1),(x2,y2),...,(xm,ym)}进行学习，建立一个从输入空间X到输出空间Y的映射f：X→Y. 对二分类任务，通常令Y={-1,+1}或{0,1};对多分类任务，|Y|＞2；对回归任务，Y=R,R为实数集

 学得模型后，使用其进行预测的过程称为”测试”（testing），被预测的样本称为”测试样本”（testing sample）例如在学得f后，对测试例x，可得其预测标记y=f（x）

 我们还可以给孔子哥做”聚类”（clustering），即将训练集中的记录分成若干组，每组称为一个”簇”（cluster）；这些自从形成的簇可能对应一些潜在的概念划分。这样的学习过程有助于我们了解数据内在的规律，能够更深入的分析数据建立基础

 根据训练数据是否拥有标记信息，学习任务大概划分为两类：”监督学习”（supervised learning）和”无监督学习”（unsupervised learning），分类和回归是前者的代表，而聚类则是后者的代表

 需注意的是，机器学习的目标是使学得的模型能够更好地适用于”新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本，学得模型适用于新样本的能力，称为”泛化”（generalizatiom）能力. 具有强泛化能力的模型能够很好地适用于整个样本空间，于是，尽管训练集通常只是样本的一小部分采样，但我们仍然希望它能够很好地反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作的很好，通常假设样本空间中全体样本服从一个未知”分布”（distribution）D，我们获得的每个样本都是独立地从这个分布上取样获得的，既”独立同分布”（independent and identically distributed，简称i.i.d）. 一般而言，训练样本越多，我们得到的关于D的信息越多，这样越可能通过学习获得具有强泛化能力的模型

 

作者自认才疏学浅，对机器学习仅略知皮毛，若文章中有错谬之处，还望各位能够不吝告知，斧正错误

 

 

 